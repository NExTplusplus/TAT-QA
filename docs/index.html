<!DOCTYPE html>
<html lang="en">
    <head>
        <meta http-equiv="content-type" content="text/html; charset=UTF-8">
        <meta charset="utf-8">
        <meta name="renderer" content="webkit">
        <link rel="icon" sizes="192x192" href="assets/next.jpeg">
        <title>TAT-QA: A Question Answering Benchmark on a Hybrid of Tabular and Textual Content in Finance</title>
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="description" content="TAT-QA: A Question Answering Benchmark on a Hybrid of Tabular and Textual Content in Finance">
        <meta name="author" content="Fengbin Zhu, Wenqiang Lei, Chao Wang, Fuli Feng">
        <link href="styles/bootstrap.min.css" rel="stylesheet">
        <link href="styles/common.css" rel="stylesheet">
    </head>

    <body data-spy="scroll" data-target=".navbar">
        <nav class="navbar navbar-default navbar-fixed-top">
            <div class="container">
                <!-- Brand and toggle get grouped for better mobile display -->
                <div class="navbar-header">
                    <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse" aria-expanded="false">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <h2 class="navbar-brand hidden-xs hidden-sm">
                        <span class="logo">TAT-QA</span>
                        <span class="description">QA over Real-world Tabular&Textual Content</span>
                    </h2>

                    <h2 class="navbar-brand hidden-md hidden-lg">
                        <span class="logo">TAT-QA</span>
                    </h2>
                </div>

                <div class="collapse navbar-collapse" id="navbar-collapse">
                    <ul class="nav navbar-nav navbar-right">
                        <li><a class="page-scroll" href="#introduction">Introduction</a></li>
                        <li><a class="page-scroll" href="#start">Getting Started</a></li>
                        <li><a class="page-scroll" href="#leaderboard">Leaderboard</a></li>
                        <li><a class="page-scroll" href="#submission">Submission</a></li>
                        <li><a class="page-scroll" href="#contact">Contact</a></li>
                    </ul>
                </div>
            </div>
        </nav>

        <!-- linked this part-->
        <section id="introduction" class="scrollable-section">
            <div class="container">
                <h3>Introduction</h3>
                <p>
                    <b>TAT-QA</b> (<b>T</b>abular <b>A</b>nd <b>T</b>extual dataset for <b>Q</b>uestion <b>A</b>nswering) is a large-scale QA dataset,
                    aiming to stimulate progress of QA research over more complex and realistic tabular and textual data, especially those requiring numerical reasoning.
                </p>
                <p>The unique features of TAT-QA include:</p>

                <ul>
                    <li>The context given is hybrid,  comprising a <ins>semi-structured table </ins> and <ins>at least two relevant paragraphs</ins> that describe, analyze or complement the table; </li>
                    <li>The questions are generated by the humans with rich <ins>financial knowledge</ins>, most are practical; </li>
                    <li>The answer forms are diverse, including <ins>single span</ins>,  <ins>multiple spans</ins> and <ins>free-form</ins>; </li>
                    <li>To answer the questions, various numerical reasoning capabilities are usually required, including  <ins>addition (+)</ins>, <ins>subtraction (-)</ins>, <ins>multiplication (x)</ins>, <ins>division (/)</ins>, <ins>counting</ins>, <ins>comparison</ins>, <ins>sorting</ins>, and <ins>their compositions</ins>; </li>
                    <li>In addition to the ground-truth answers, the corresponding derivations and scale are also provided if any. </li>
                </ul>
                <p>
                    In total, TAT-QA contains <b>16,552</b> questions associated with <b>2,757</b> hybrid contexts from real-world financial reports.
               </p>
                <p>
                    The following is an example of TAT-QA. The left dashed line box shows a hybrid context.
                    The rows with blue background are row header while the column with grey is column header.
                    The right solid line box shows corresponding question, answer with its scale, and derivation to arrive at the answer.
                </p>


                <img src="assets/tatqa-sample.png" alt="TAT-QA Sample" width="100%" >
                    <br>

                For more information, please read our ACL 2021 paper  <a href="https://aclanthology.org/2021.acl-long.254.pdf" target="_blank">[PDF]</a>.

      
                
        <p>

     <a href="https://nextplusplus.github.io/TAT-DQA/" target="_blank">TAT-DQA</a> is a new large-scale Document Visual QA (VQA) dataset, which is constructed by extending the TAT-QA.

    Please check out it if you are interested in the new task.
     
      </p>
            </div>
        </section>

        <section id="start" class="scrollable-section">
            <div class="container">
                <h3>Getting Started</h3>

                Download a copy of the dataset in json format:

                <ul>
                        <li>
                            <a href="https://github.com/NExTplusplus/tat-qa/blob/master/dataset_raw/tatqa_dataset_train.json" target="_blank">Training set</a>
                            <small>[MD5: cc5026bdfe51bb47d63e6c3d31714951]</small>
                        </li>
                        <li>
                            <a href="https://github.com/NExTplusplus/tat-qa/blob/master/dataset_raw/tatqa_dataset_dev.json" target="_blank">Dev set</a>
                            <small>[MD5: 0b24a68b35fd814df5ad12cba548a8ea]</small>
                        </li>
                        <li>
                            <a href="https://github.com/NExTplusplus/tat-qa/blob/master/dataset_raw/tatqa_dataset_test.json" target="_blank">Test set</a>
                            <small>[MD5: c6ccc2beecaed12fc070c3df102ca019]</small>
                        </li>
                </ul>

<pre>
{
  "table": {                                                            <em class="comment"># The tabular data in a hybrid context</em>
    "uid": "3ffd9053-a45d-491c-957a-1b2fa0af0570",                      <em class="comment"># The unique id of a table</em>
    "table": [                                                          <em class="comment"># The table content which is 2d-array</em>
      [
        "",
        "2019",
        "2018",
        "2017"
      ],
      [
        "Fixed Price",
        "$  1,452.4",
        "$  1,146.2",
        "$  1,036.9"
      ],
      ...
    ]
  },
  "paragraphs": [                                                        <em class="comment"># The textual data in a hybrid context comprising at least two associated paragraphs to the table</em>
    {
      "uid": "f4ac7069-10a2-47e9-995c-3903293b3d47",                     <em class="comment"># The unique id of a paragraph</em>
      "order": 1,                                                        <em class="comment"># The order of the paragraph in all associated paragraphs, starting from 1</em>
      "text": "Sales by Contract Type: Substantially all of              <em class="comment"># The content of the paragraph</em>
       our contracts are fixed-price type contracts.
       Sales included in Other contract types represent cost
       plus and time and material type contracts."
    },
    ...
  ],
  "questions": [                                                         <em class="comment"># The questions associated to the hybrid context</em>
    {
      "uid": "eb787966-fa02-401f-bfaf-ccabf3828b23",                     <em class="comment"># The unique id of a question</em>
      "order": 2,                                                        <em class="comment"># The order of the question in all questions, starting from 1</em>
      "question": "What is the change in Other in 2019 from 2018?",      <em class="comment"># The question itself</em>
      "answer": -12.6,                                                   <em class="comment"># The ground-truth answer</em>
      "derivation": "44.1 - 56.7",                                       <em class="comment"># The derivation that can be executed to arrive at the ground-truth answer</em>
      "answer_type": "arithmetic",                                       <em class="comment"># The answer type including `span`, `spans`, `arithmetic` and `counting`.</em>
      "answer_from": "table-text",                                       <em class="comment"># The source of the answer including `table`, `table` and `table-text`</em>
      "rel_paragraphs": [                                                <em class="comment"># The orders of the paragraphs that are relied to infer the answer if any.</em>
        "2"
      ],
      "req_comparison": false,                                           <em class="comment"># A flag indicating if `comparison/sorting` is needed to answer the question whose answer is a single span or multiple spans</em>
      "scale": "million"                                                 <em class="comment"># The scale of the answer including `None`, `thousand`, `million`, `billion` and `percent`</em>
    }
  ]
}
</pre>

            </div>
        </section>

        <section id="leaderboard" class="scrollable-section">
            <div style="background-color: #e8e8e8">
                <div class="container">
                    <h3>Leaderboard</h3>

                    <div class="table-responsive">
                    <table class="table well">
                        <thead class="thead-dark">
                        <tr>
                            <th>Rank</th>
                            <th>Model Name</th>
                            <th>Team Name</th>
                            <th>Exact Match</th>
                            <th>F1</th>
                            <th>Created</th>
                            <th>Paper</th>
                            <th>Codes</th>
                        </tr>
                        </thead>

                        <tbody>
                        <tr>
                            <td>-</td>
                            <td>Human Performance</td>
                            <td>-</td>
                            <td>84.1</td>
                            <td>90.8</td>
                            <td>-</td>
                            <td>-</td>
                            <td>-</td>
                        </tr>
                        <tr>
                            <td>1</td>
                            <td>TAT-LLM (70B)</td>
                            <td>NExT</td>
                            <td><b>81.4</b></td>
                            <td><b>88.4</b></td>
                            <td>20 Jan 2024</td>
                            <td><a href="https://arxiv.org/pdf/2401.13223.pdf" target="_blank">Paper</a></td>
                            <td>N.A.</td>
                        </tr>
                         <tr>
                            <td>2</td>
                            <td>MATATA-8B</td>
                            <td>Docugami</td>
                            <td>77.6</td>
                            <td>84.9</td>
                            <td>9 Dec 2024</td>
                            <td><a href="https://arxiv.org/pdf/2411.18915" target="_blank">Paper</a></td>
                            <td>N.A.</td>
                        </tr>
                        <tr>
                            <td>3</td>
                            <td>TAT-LLM (13B)</td>
                            <td>NExT</td>
                            <td>77.5</td>
                            <td>85.9</td>
                            <td>20 Jan 2024</td>
                            <td><a href="https://arxiv.org/pdf/2401.13223.pdf" target="_blank">Paper</a></td>
                            <td>N.A.</td>
                        </tr>
                        <tr>
                            <td>4</td>
                            <td>Code Generation for Table-Text Question using LLM (70B)</td>
                            <td>Anonymous</td>
                            <td>76.8</td>
                            <td>84.7</td>
                            <td>21 Sep 2023</td>
                            <td>N.A.</td>
                            <td>N.A.</td>
                        </tr>
                        <tr>
                            <td>5</td>
                            <td>TAT-LLM (7B)</td>
                            <td>NExT</td>
                            <td>76.4</td>
                            <td>85.1</td>
                            <td>20 Jan 2024</td>
                            <td><a href="https://arxiv.org/pdf/2401.13223.pdf" target="_blank">Paper</a></td>
                            <td>N.A.</td>
                        </tr>
                        <tr>
                            <td>6</td>
                            <td>AeNER: Attention-enhanced Numerical Embeddings for Reasoning</td>
                            <td>Gryffindor</td>
                            <td>75.0</td>
                            <td>83.2</td>
                            <td>16 May 2022</td>
                            <td>N.A.</td>
                            <td>N.A.</td>
                        </tr>
                        <tr>
                            <td>7</td>
                            <td>MATATA-3.8B</td>
                            <td>Docugami</td>
                            <td>74.2</td>
                            <td>82.4</td>
                            <td>9 Dec 2024</td>
                            <td><a href="https://arxiv.org/pdf/2411.18915" target="_blank">Paper</a></td>
                            <td>N.A.</td>
                        </tr>
                        <tr>
                            <td>8</td>
                            <td>Code Generation for Table-Text Question using LLM (13B)</td>
                            <td>Anonymous</td>
                            <td>73.7</td>
                            <td>81.8</td>
                            <td>21 Sep 2023</td>
                            <td>N.A.</td>
                            <td>N.A.</td>
                        </tr>
                         <tr>
                            <td>9</td>
                            <td>Encore</td>
                            <td>HIT-SCIR</td>
                            <td>71.8</td>
                            <td>80.1</td>
                            <td>24 Oct 2022</td>
                            <td><a href="https://aclanthology.org/2024.acl-long.582/" target="_blank">Paper</a></td>
                            <td><a href="https://github.com/zirui-HIT/Encore" target="_blank">Code</a></td>
                        </tr>
                        <tr>
                            <td>10</td>
                            <td>KFEX-N: A Table-Text QA Model with Knowledge-Fused Encoder & EX-N Tree Decoder</td>
                            <td>CWQian China</td>
                            <td>71.0</td>
                            <td>79.5</td>
                            <td>29 Oct 2023</td>
                            <td><a href="https://www.sciencedirect.com/science/article/pii/S0925231224005666" target="_blank">Paper</a></td>
                            <td>N.A.</td>
                        </tr>
                        <tr>
                            <td>11</td>
                            <td>MVGE: Multi-View Graph Encoder for Answering Hybrid Numerical Reasoning Question</td>
                            <td>Weiyifan@CASIA</td>
                            <td>70.9</td>
                            <td>79.1</td>
                            <td>23 Dec 2022</td>
                            <td><a href="https://arxiv.org/pdf/2305.03458.pdf" target="_blank">Paper</a></td>
                            <td><a href="https://github.com/weiyifan1023/MVGE" target="_blank">Code</a></td>
                        </tr>
                        <tr>
                            <td>12</td>
                            <td>RegHNT: Relational graph neural network with special multitask decoder</td>
                            <td>LFyimi@CASIA China</td>
                            <td>70.3</td>
                            <td>77.9</td>
                            <td>5 May 2022</td>
                            <td><a href="https://arxiv.org/pdf/2209.07692.pdf" target="_blank">Paper</a></td>
                            <td><a href="https://github.com/lfy79001/RegHNT" target="_blank">Code</a></td>
                          </tr>
                        <tr>
                            <td>13</td>
                            <td>Code Generation for Table-Text Question using LLM (7B)</td>
                            <td>Anonymous</td>
                            <td>68.4</td>
                            <td>77.3</td>
                            <td>21 Sep 2023</td>
                            <td>N.A.</td>
                            <td>N.A.</td>
                        </tr>
                         <tr>
                            <td>14</td>
                            <td>UniRPG: Unified Discrete Reasoning over Table and Text as Program Generation</td>
                            <td>JD AI Research</td>
                            <td>67.2</td>
                            <td>76.0</td>
                            <td>24 Feb 2022</td>
                            <td><a href="https://arxiv.org/pdf/2210.08249.pdf" target="_blank">Paper</a></td>
                            <td><a href="https://github.com/JD-AI-Research-NLP/UniRPG" target="_blank">Code</a></td>
                        </tr>
                       
                        <tr>
                            <td>15</td>
                            <td>RSTQA: Rounds Specified numerical reasoning for Table-Text QA</td>
                            <td>NLP2CT@UM Macau</td>
                            <td>66.8</td>
                            <td>75.0</td>
                            <td>30 Oct 2023</td>
                            <td>N.A.</td>
                            <td>N.A.</td>
                        </tr>  
                        <tr>
                            <td>16</td>
                            <td>SoarGraph: Semantic-Oriented Hierarchical Graphs</td>
                            <td>NExT</td>
                            <td>65.4</td>
                            <td>75.3</td>
                            <td>8 Sep 2022</td>
                            <td><a href="https://dl.acm.org/doi/abs/10.1145/3543873.3587598" target="_blank">Paper</a></td>
                            <td>N.A.</td>
                        </tr>
                         <tr>
                            <td>17</td>
                            <td>UniPCQA</td>
                            <td>NExT / CUHK</td>
                            <td>63.9</td>
                            <td>72.2</td>
                            <td>22 Oct 2022</td>
                            <td><a href="https://arxiv.org/pdf/2210.08817.pdf" target="_blank">Paper</a></td>
                            <td>N.A.</td>
                        </tr>
                        <tr>
                            <td>18</td>
                            <td>MHST: Multi-Head with Sequence to Expression Tree</td>
                            <td>NExT</td>
                            <td>63.6</td>
                            <td>72.7</td>
                            <td>24 May 2022</td>
                            <td><a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548422" target="_blank">Paper</a></td>
                            <td>N.A.</td>
                        </tr>
                         
                          <tr>
                            <td>19</td>
                            <td>GANO: GNN for Tabular and Textual QA with Numerical Reasoning</td>
                            <td>iLab@AIST Japan</td>
                            <td>61.9</td>
                            <td>72.1</td>
                            <td>15 Jul 2022</td>
                            <td><a href="https://aclanthology.org/2022.aacl-main.72.pdf" target="_blank">Paper</a></td>
                            <td>N.A.</td>
                        </tr>
                        <tr>
                            <td>20</td>
                            <td>TBC</td>
                            <td>Anonymous</td>
                            <td>60.8</td>
                            <td>68.7</td>
                            <td>22 Jun 2022</td>
                            <td>N.A.</td>
                            <td>N.A.</td>
                        </tr>
                         <tr>
                            <td>21</td>
                            <td>FinMath: Injecting a Tree-structured Solver for Question Answering over Financial Reports</td>
                            <td>FinMath@NEU China</td>
                            <td>58.3</td>
                            <td>68.2</td>
                            <td>6 Aug 2022</td>
                            <td><a href="http://www.lrec-conf.org/proceedings/lrec2022/pdf/2022.lrec-1.661.pdf" target="_blank">Paper</a></td>
                            <td>N.A.</td>
                        </tr>
                         <tr>
                            <td>22</td>
                            <td>KIQA: Knowledge-infused QA Model for Table and Text</td>
                            <td>iLab@AIST Japan</td>
                            <td>58.2</td>
                            <td>67.4</td>
                            <td>23 Feb 2022</td>
                            <td><a href="https://aclanthology.org/2022.deelio-1.6.pdf" target="_blank">Paper</a></td>
                            <td>N.A.</td>
                        </tr>
                     
                         <tr>
                            <td>23</td>
                            <td>LETTER: Logic Enhanced Table-Text Reasoning</td>
                            <td>OnceAgain</td>
                            <td>56.1</td>
                            <td>64.3</td>
                            <td>17 Feb 2022</td>
                            <td>N.A.</td>
                            <td>N.A.</td>
                        </tr>
                          <tr>
                            <td>24</td>
                            <td>TeaBReaC-pretrained T5-3B</td>
                            <td>SBU / Allen AI</td>
                            <td>55.8</td>
                            <td>63.8</td>
                            <td>17 Jun 2022</td>
                            <td><a href="https://arxiv.org/pdf/2205.12496.pdf" target="_blank">Paper</a></td>
                            <td>N.A.</td>
                        </tr>
                         <tr>
                            <td>25</td>
                            <td>OPERA-H</td>
                            <td>Hero_Dirk</td>
                            <td>55.2</td>
                            <td>63.8</td>
                            <td>9 Oct 2022</td>
                            <td>N.A.</td>
                            <td>N.A.</td>
                        </tr>
                        
                        <tr>
                            <td>26</td>
                            <td>GenQA:Generative model for QA from table and text</td>
                            <td>IITJ@India</td>
                            <td>55.1</td>
                            <td>65.6</td>
                            <td>7 Feb 2023</td>
                            <td>N.A.</td>
                            <td>N.A.</td>
                        </tr>
                        <tr>
                            <td>27</td>
                            <td>Baseline - TagOp</td>
                            <td>NExT</td>
                            <td>50.1</td>
                            <td>58.0</td>
                            <td>13 May 2021</td>
                            <td><a href="https://aclanthology.org/2021.acl-long.254/" target="_blank">Paper</a></td>
                            <td><a href="https://github.com/NExTplusplus/tat-qa" target="_blank">Code</a></td>
                        </tr>
                        </tbody>
                    </table>
                    </div>

                </div>
            </div>
        </section>

        <section id="submission" class="scrollable-section">
            <div class="container">
                <h3>Submission</h3>
                <p>
                To evaluate your models, we have also made available the evaluation script we will use for official evaluation,
                To run the evaluation, use
                </p>
                <pre>python tatqa_eval.py --gold_path=:path_to_dev --pred_path=:path_to_predictions</pre>

                <h4>Predictions Format</h4>
                <p> The predictions file in JSON format contains a dictionary with question ids as keys and the predictions as values
                    (each prediction shall include both `answer` and `scale` in an array). For example,
                </p>
                <pre>
{
 "9337c3e6-c53f-45a9-836a-02c474ceac16": [
    "4.6",
    "percent"
  ],
  "c4170232-e89c-487a-97c5-afad45e9d702": [
    "16",
    "thousand"
  ],
  "d81d1ae7-363c-4b47-8eea-1906fef33856": [
    ["2018", "2019"],
    ""
  ]
  ...
}
</pre>
                <p>We also provide a <a href="https://github.com/NExTplusplus/tat-qa/blob/master/sample_prediction.json" target="_blank" >sample prediction file </a> (on Dev) for your reference.</p>

                <pre>python tatqa_eval.py --gold_path=dataset_raw/tatqa_dataset_dev.json --pred_path=sample_prediction.json</pre>
                <h4>Submission</h4>
                <p>
                    Please email the prediction file of the test set with the following information to us:
                    <ul>
                        <li>Model name with a brief description of your model</li>
                        <li>Team name</li>
                        <li>Contact person</li>
                        <li>Email of the contact person</li>
                        <li>Link to the paper (if any)</li>
                        <li>Link to the code repository (if any)</li>
                    </ul>
                </p>
                <p>
                Please give us up to two weeks to evaluate your submission and we will add your model to the leaderboard.
                </p>
            </div>
        </section>

        <section id="contact" class="scrollable-section">
            <div class="container">
                <h3>Contact</h3>
                <p>
                    The TAT-QA dataset is under the license of <a href="https://creativecommons.org/licenses/by/4.0/">Creative Commons (CC BY) Attribution 4.0 International.</a>  
                 </p>  
                 <p>
                    For more information, please contact the author: Fengbin ZHU <a href="mailto:fengbinzhu@u.nus.edu">fengbinzhu@u.nus.edu</a>
                </p>
                <p>
                    Please kindly cite our work if you use our dataset or codes, thank you.
                </p>
<pre>

@inproceedings{zhu2021tat,
    title = "{TAT}-{QA}: A Question Answering Benchmark on a Hybrid of Tabular and Textual Content in Finance",
    author = "Zhu, Fengbin  and
      Lei, Wenqiang  and
      Huang, Youcheng  and
      Wang, Chao  and
      Zhang, Shuo  and
      Lv, Jiancheng  and
      Feng, Fuli  and
      Chua, Tat-Seng",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.254",
    doi = "10.18653/v1/2021.acl-long.254",
    pages = "3277--3287"
}

</pre>
            </div>
            </div>
        </section>

        <footer class="footer" style="padding-top: 50px;">
            <div class="container">
                <hr>
                <p style="font-style: italic; text-align: center">
                    Copyright &copy; 2018-2021 NExT++ /
                    <a class="black" href="http://www.nextcenter.org/privacy-policy" target="_blank" >Privacy Policy</a> /
                    <a class="black" href="http://www.nextcenter.org/terms-conditions" target="_blank" >Terms &amp; Conditions</a>
                </p>
            </div>
        </footer>

        <script type="text/javascript" src="scripts/jquery-3.2.1.min.js"></script>
        <script type="text/javascript" src="scripts/bootstrap.min.js"></script>
        <script type="text/javascript" src="scripts/jquery.easing.min.js"></script>
        <script type="text/javascript" src="scripts/scrolling-nav.js"></script>
    </body>
</html>
